# Web Scraping Guide - Mauvanban.vn

## ğŸ•·ï¸ Crawl Dá»¯ Liá»‡u Tá»« Mauvanban.vn

Script nÃ y sáº½ crawl categories vÃ  documents tá»« website mauvanban.vn.

---

## CÃ i Äáº·t Dependencies

```bash
pip install beautifulsoup4 requests lxml
```

Hoáº·c:

```bash
pip install -r requirements.txt
```

---

## Cháº¡y Script Crawl

```bash
python scripts/crawl_mauvanban.py
```

---

## Script Sáº½ LÃ m GÃ¬?

1. âœ… Crawl danh sÃ¡ch categories tá»« trang chá»§
2. âœ… Crawl documents tá»« má»—i category (giá»›i háº¡n 5 docs/category)
3. âœ… Crawl chi tiáº¿t má»—i document (title, description, content, guide)
4. âœ… LÆ°u vÃ o file JSON: `scripts/crawled_data.json`
5. âœ… Tá»± Ä‘á»™ng import vÃ o database

---

## LÆ°u Ã Quan Trá»ng

### âš ï¸ Selectors Cáº§n Äiá»u Chá»‰nh

Script hiá»‡n táº¡i sá»­ dá»¥ng **selectors giáº£ Ä‘á»‹nh**. Báº¡n cáº§n inspect website thá»±c táº¿ vÃ  sá»­a láº¡i:

```python
# Trong hÃ m crawl_categories()
category_links = soup.find_all('a', class_='category-link')  # â† Sá»­a class nÃ y

# Trong hÃ m crawl_documents()
doc_items = soup.find_all('div', class_='document-item')  # â† Sá»­a class nÃ y

# Trong hÃ m crawl_document_detail()
description_elem = soup.find('div', class_='description')  # â† Sá»­a class nÃ y
content_elem = soup.find('div', class_='content')  # â† Sá»­a class nÃ y
```

### ğŸ” CÃ¡ch TÃ¬m Selectors ÄÃºng

1. **Má»Ÿ mauvanban.vn** trong Chrome
2. **Right-click** vÃ o element â†’ **Inspect**
3. **Xem HTML structure** vÃ  class names
4. **Sá»­a láº¡i selectors** trong script

**VÃ­ dá»¥:**

Náº¿u HTML thá»±c táº¿ lÃ :
```html
<div class="category-menu">
  <a href="/hop-dong" class="cat-link">Há»£p Ä‘á»“ng</a>
</div>
```

ThÃ¬ sá»­a thÃ nh:
```python
category_links = soup.find_all('a', class_='cat-link')
```

---

## Fallback Data

Náº¿u crawling tháº¥t báº¡i (do selectors sai hoáº·c website block), script sáº½ dÃ¹ng **fallback data**:

```python
categories = [
    {'name': 'Há»£p Ä‘á»“ng', 'url': f'{BASE_URL}/hop-dong', 'slug': 'hop-dong'},
    {'name': 'ÄÆ¡n tá»«', 'url': f'{BASE_URL}/don-tu', 'slug': 'don-tu'},
    {'name': 'BiÃªn báº£n', 'url': f'{BASE_URL}/bien-ban', 'slug': 'bien-ban'},
    {'name': 'Giáº¥y á»§y quyá»n', 'url': f'{BASE_URL}/giay-uy-quyen', 'slug': 'giay-uy-quyen'},
]
```

---

## TÃ¹y Chá»‰nh

### Giá»›i háº¡n sá»‘ lÆ°á»£ng

```python
# Trong main()
for category in categories[:5]:  # â† Crawl 5 categories Ä‘áº§u
    docs = crawl_documents(category['url'], category['name'], limit=5)  # â† 5 docs/category
```

### Delay giá»¯a requests

```python
time.sleep(1)  # â† TÄƒng lÃªn 2-3 giÃ¢y náº¿u bá»‹ block
```

---

## Output

### File JSON

```json
[
  {
    "name": "Há»£p Ä‘á»“ng",
    "slug": "hop-dong",
    "url": "https://mauvanban.vn/hop-dong",
    "documents": [
      {
        "title": "Há»£p Ä‘á»“ng thuÃª nhÃ ",
        "description": "Máº«u há»£p Ä‘á»“ng...",
        "content": "Cá»˜NG HÃ’A...",
        "url": "https://mauvanban.vn/hop-dong/thue-nha",
        "guide": {
          "usage_guide": "Sá»­ dá»¥ng khi...",
          "filling_guide": "Äiá»n Ä‘áº§y Ä‘á»§..."
        }
      }
    ]
  }
]
```

### Database

Tá»± Ä‘á»™ng táº¡o:
- Categories vá»›i slug
- Documents vá»›i code tá»± Ä‘á»™ng (VD: HOP-001, HOP-002)
- DocumentGuides vá»›i thÃ´ng tin hÆ°á»›ng dáº«n

---

## Troubleshooting

### Lá»—i: No categories found

**NguyÃªn nhÃ¢n:** Selectors khÃ´ng Ä‘Ãºng

**Giáº£i phÃ¡p:**
1. Inspect website
2. Sá»­a selectors trong `crawl_categories()`
3. Hoáº·c dÃ¹ng fallback data

### Lá»—i: Connection timeout

**NguyÃªn nhÃ¢n:** Website cháº­m hoáº·c block

**Giáº£i phÃ¡p:**
```python
response = requests.get(url, timeout=30)  # TÄƒng timeout
time.sleep(3)  # TÄƒng delay
```

### Lá»—i: 403 Forbidden

**NguyÃªn nhÃ¢n:** Website block bot

**Giáº£i phÃ¡p:**
```python
headers = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
}
response = requests.get(url, headers=headers)
```

---

## Alternative: Manual Data Entry

Náº¿u crawling khÃ´ng hoáº¡t Ä‘á»™ng, báº¡n cÃ³ thá»ƒ:

1. **DÃ¹ng seed script** cÃ³ sáºµn:
```bash
python scripts/seed_data.py
```

2. **Táº¡o thá»§ cÃ´ng qua Swagger UI**:
- Categories: `POST /api/admin/categories`
- Documents: `POST /api/admin/documents/json`

3. **Import tá»« CSV**:
Táº¡o file CSV vÃ  viáº¿t script import

---

## Best Practices

- âœ… Respect robots.txt
- âœ… Add delays between requests (1-2 seconds)
- âœ… Use proper User-Agent
- âœ… Don't overload the server
- âœ… Cache results to avoid re-crawling
- âš ï¸ Check website's Terms of Service

---

## Next Steps

1. **Cháº¡y script** vÃ  xem káº¿t quáº£
2. **Kiá»ƒm tra** `crawled_data.json`
3. **Verify** data trong database
4. **Adjust selectors** náº¿u cáº§n
5. **Run again** Ä‘á»ƒ crawl thÃªm data

---

## Support

Náº¿u gáº·p váº¥n Ä‘á»:
1. Check console output Ä‘á»ƒ xem lá»—i
2. Inspect website HTML structure
3. Adjust selectors accordingly
4. Use fallback data if needed
